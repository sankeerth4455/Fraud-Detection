# -*- coding: utf-8 -*-
"""CreditCardFraud_SupervisedLearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VmwBkcLlQIUGK4Fv8lZbsM10nUmVvilG
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

# Loading Data
df = pd.read_csv('/content/drive/MyDrive/fraudTest.csv')
df.head(10)

# Data Description
print(f"The columns in this dataset are: {df.columns}")
print(f"The shape of this dataset is: {df.shape}")
print("Number of unique values in each column")
df.nunique()

# Filtering Columns
df_filter = df[['cc_num','amt', 'zip', 'city_pop', 'category','gender', 'is_fraud']]
print('Data Preview:')
print(df_filter.head())
print(f"The columns in this dataset are: {df_filter.columns}")
print(f"The shape of this dataset is: {df_filter.shape}")
print("Number of unique values in each column")
df_filter.nunique()

# Encoding Columns
df_encoded = df_filter.copy()
df_encoded['category'] = LabelEncoder().fit_transform(df_encoded['category'])
df_encoded = pd.get_dummies(df_encoded, columns=['gender'])
df_encoded.rename(columns={'gender_F':'female', 'gender_M':'male'}, inplace=True)
df_encoded['male'] = df_encoded['male'].astype(int)
df_encoded['female'] = df_encoded['female'].astype(int)
df_encoded = df_encoded[['cc_num', 'amt','zip','city_pop','category','male','female','is_fraud']]
print('Data Preview:')
print(df_encoded.head())
print(f"The columns in this dataset are: {df_encoded.columns}")
print(f"The shape of this dataset is: {df_encoded.shape}")
print("Number of unique values in each column")
df_encoded.nunique()

"""#### Dealing With Imablanced Data"""

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

final_sl_data = df_encoded.copy()
final_sl_data = final_sl_data.drop('is_fraud', axis=1)
print('Data Preview:')
print(final_sl_data.head())
scaled_final_sl_data = StandardScaler().fit_transform(final_sl_data)
scaled_final_sl_data = pd.DataFrame(scaled_final_sl_data, columns = final_sl_data.columns)
scaled_final_sl_data['is_fraud'] = df_encoded['is_fraud']
print('Data Preview:')
print(scaled_final_sl_data.head())

train_df,test_df = train_test_split(scaled_final_sl_data, test_size = 0.2, stratify = df_encoded['is_fraud'], random_state = 310)

print('Data Preview:')
print(train_df.head())
print(f"The columns in this dataset are: {train_df.columns}")
print(f"The shape of this dataset is: {train_df.shape}")
print("Number of unique values in each column")
print(train_df.nunique())
print('Distribution of target:')
print(train_df['is_fraud'].value_counts())

print('Data Preview:')
print(test_df.head())
print(f"The columns in this dataset are: {test_df.columns}")
print(f"The shape of this dataset is: {test_df.shape}")
print("Number of unique values in each column")
print(test_df.nunique())
print('Distribution of target:')
print(test_df['is_fraud'].value_counts())

# Implimenting SMOTE
train_smote_df = train_df.copy()
smote = SMOTE(sampling_strategy='auto', random_state=310)
X_smote, y_smote = smote.fit_resample(train_smote_df.drop('is_fraud', axis=1), train_smote_df['is_fraud'])
train_smote_df_resampled = pd.DataFrame(X_smote, columns=train_smote_df.drop('is_fraud', axis=1).columns)
train_smote_df_resampled['is_fraud'] = y_smote
print('Data Preview:')
print(train_smote_df_resampled.head())
print(f"The columns in this dataset are: {train_smote_df_resampled.columns}")
print(f"The shape of this dataset is: {train_smote_df_resampled.shape}")
print("Number of unique values in each column")
print(train_smote_df_resampled.nunique())
print('Distribution of target:')
print(train_smote_df_resampled['is_fraud'].value_counts())

"""#### Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report

# Training and Tesing Data for model
x_train_lr = train_smote_df_resampled.drop('is_fraud', axis=1)
y_train_lr = train_smote_df_resampled['is_fraud']
x_test_lr = test_df.drop('is_fraud', axis=1)
y_test_lr = test_df['is_fraud']

# LR Model
lr_model = LogisticRegression()

param_grid = {
    'C': [0.01, 0.1, 1],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'saga'],
    'max_iter': [100, 250, 500],
    'random_state': [310]
    }

gridsearch = GridSearchCV(lr_model, param_grid, cv=3, scoring='f1')

gridsearch.fit(x_train_lr, y_train_lr)
best_model = gridsearch.best_estimator_
print(best_model)

pred_lr = best_model.preddict(x_test_lr)

# Metrics
report = classification_report(y_test_lr, pred_lr)
print(report)
cm = confusion_matrix(y_test_lr, pred_lr)
plt.figure(figsize=(6,6))
sns.heatmap(cm, fmt='d', cmap='inferno', xticklabels=['Not Fraud', 'Fraud'], yticklabels=['Not Fraud', 'Fraud'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Plotting Results
plot_df_lr = pd.DataFrame()
plot_df_lr['is_fraud'] = y_test_lr
plot_df_lr['predicted_fraud'] = pred_lr

TP = (plot_df_lr['is_fraud'] == 1) & (plot_df_lr['predicted_fraud'] == 1)
TN = (plot_df_lr['is_fraud'] == 0) & (plot_df_lr['predicted_fraud'] == 0)
FP = (plot_df_lr['is_fraud'] == 0) & (plot_df_lr['predicted_fraud'] == 1)
FN = (plot_df_lr['is_fraud'] == 1) & (plot_df_lr['predicted_fraud'] == 0)

plt.figure(figsize=(10,10))
plt.scatter(plot_df_lr[TP][ : , 0], plot_df_lr[TP][ : , 1], c='green',label='True Positives')
plt.scatter(plot_df_lr[TN][ : , 0], plot_df_lr[TN][ : , 1], c='red',label='True Negatives')
plt.scatter(plot_df_lr[FP][ : , 0], plot_df_lr[FP][ : , 1], c='yellow',label='True Negatives')
plt.scatter(plot_df_lr[FN][ : , 0], plot_df_lr[FN][ : , 1], c='orange',label='True Negatives')
plt.title('Logistic Regression')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()

"""#### XGBoost Model"""

from xgboost import XGBClassifier

# Training and Tesing Data for model
x_train_XGB = train_df.drop('is_fraud', axis=1)
y_train_XGB = train_df['is_fraud']
x_test_XGB = test_df.drop('is_fraud', axis=1)
y_test_XGB = test_df['is_fraud']

# XGB Model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

param_grid = {
    'n_estimators': [100, 300, 500],
    'learning_rate': [0.01, 0.1, 0.3],
    'max_depth': [3, 5, 7],
    'scale_pos_weight': [sum(y_train_XGB['is_fraud'] == 0) / sum(y_train_XGB['is_fraud'] == 1)],
    'seed': [310]
}

gridsearch = GridSearchCV(xgb_model, param_grid, cv=3, scoring='f1',n_jobs=-1)
gridsearch.fit(x_train_XGB, y_train_XGB)

best_model = gridsearch.best_estimator_
print(best_model)

pred_XGB = best_model.predict(x_test_XGB)

# Metrics
report = classification_report(y_test_XGB, pred_XGB)
print(report)
cm = confusion_matrix(y_test_XGB, pred_XGB)
plt.figure(figsize=(6,6))
sns.heatmap(cm, fmt='d', cmap='inferno', xticklabels=['Not Fraud', 'Fraud'], yticklabels=['Not Fraud', 'Fraud'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Plotting Results
plot_df_XGB = pd.DataFrame()
plot_df_XGB['is_fraud'] = y_test_XGB
plot_df_XGB['predicted_fraud'] = pred_XGB

TP = (plot_df_XGB['is_fraud'] == 1) & (plot_df_XGB['predicted_fraud'] == 1)
TN = (plot_df_XGB['is_fraud'] == 0) & (plot_df_XGB['predicted_fraud'] == 0)
FP = (plot_df_XGB['is_fraud'] == 0) & (plot_df_XGB['predicted_fraud'] == 1)
FN = (plot_df_XGB['is_fraud'] == 1) & (plot_df_XGB['predicted_fraud'] == 0)

plt.figure(figsize=(10,10))
plt.scatter(plot_df_XGB[TP][ : , 0], plot_df_XGB[TP][ : , 1], c='green',label='True Positives')
plt.scatter(plot_df_XGB[TN][ : , 0], plot_df_XGB[TN][ : , 1], c='red',label='True Negatives')
plt.scatter(plot_df_XGB[FP][ : , 0], plot_df_XGB[FP][ : , 1], c='yellow',label='True Negatives')
plt.scatter(plot_df_XGB[FN][ : , 0], plot_df_XGB[FN][ : , 1], c='orange',label='True Negatives')
plt.title('Logistic Regression')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()