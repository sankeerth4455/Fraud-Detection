# -*- coding: utf-8 -*-
"""CreditCardFraud_Unsupervised.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uH3YSk7dXG_niQ-E9zskLNQZyB4fhv8R

#### Packages
"""

# Importing Packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

import warnings
warnings.filterwarnings('ignore')

# Mounting Drive
from google.colab import drive
drive.mount('/content/drive')

"""#### Data Formation"""

# Loading Data
df = pd.read_csv('/content/drive/MyDrive/fraudTest.csv')
df.head(10)

# Data Description
print(f"The columns in this dataset are: {df.columns}")
print(f"The shape of this dataset is: {df.shape}")
print("Number of unique values in each column")
df.nunique()

# Filtering Columns
df_filter = df[['cc_num','amt', 'zip', 'city_pop', 'category','gender', 'is_fraud']]
print('Data Preview:')
print(df_filter.head())
print(f"The columns in this dataset are: {df_filter.columns}")
print(f"The shape of this dataset is: {df_filter.shape}")
print("Number of unique values in each column")
df_filter.nunique()

# Encoding Columns
df_encoded = df_filter.copy()
df_encoded['category'] = LabelEncoder().fit_transform(df_encoded['category'])
df_encoded = pd.get_dummies(df_encoded, columns=['gender'])
df_encoded.rename(columns={'gender_F':'female', 'gender_M':'male'}, inplace=True)
df_encoded['male'] = df_encoded['male'].astype(int)
df_encoded['female'] = df_encoded['female'].astype(int)
df_encoded = df_encoded[['cc_num', 'amt','zip','city_pop','category','male','female','is_fraud']]
print('Data Preview:')
print(df_encoded.head())
print(f"The columns in this dataset are: {df_encoded.columns}")
print(f"The shape of this dataset is: {df_encoded.shape}")
print("Number of unique values in each column")
df_encoded.nunique()

"""#### DBScan"""

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

# Data Formaation
training_df = df_encoded.copy()
training_df = training_df.drop('is_fraud', axis=1)
print('Data Preview:')
print(training_df.head())
scaled_data = StandardScaler().fit_transform(training_df)
scaled_df = pd.DataFrame(scaled_data, columns = training_df.columns)
print('Data Preview:')
print(scaled_df.head())

# Parameter Identification
best_score = -1
best_parameters = {}

for eps in np.arange(0.1, 1.0, 0.1):
  for min_samples in range(3,10):
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    dbscan.fit(scaled_df)
    labels = dbscan.labels_
    score = silhouette_score(scaled_df, labels)
    if score > best_score:
      best_score = score
      best_parameters = {'eps': eps, 'min_samples': min_samples}

print(f"Best Score: {best_score}")
print(f"Best Parameters: {best_parameters}")

# Model
dbscan_final = DBSCAN(eps=best_parameters[0], min_samples=best_parameters[1])
dbscan_final.fit(scaled_df)
labels = dbscan.labels_
scaled_df['cluster_labels'] = labels
scaled_df['is_fraud'] = training_df['is_fraud']
print('Data Preview:')
print(scaled_df.head())
predicted_fraud = ()
for i in range(scaled_df['cluster_labels']):
  if scaled_df['cluster_labels'] == -1:
    predicted_fraud = predicted_fraud.append(1)
  else:
    predicted_fraud = predicted_fraud.append(0)
scaled_df['predicted_fraud'] = predicted_fraud
print('Data Preview:')
print(scaled_df.head())

# Validation
report = classification_report(scaled_df['is_fraud'], scaled_df['predicted_fraud'])
print(report)
cm = confusion_matrix(scaled_df['is_fraud'], scaled_df['predicted_fraud'])
plt.figure(figsize=(6,6))
sns.heatmap(cm, fmt='d', cmap='inferno', xticklabels=['Not Fraud', 'Fraud'], yticklabels=['Not Fraud', 'Fraud'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Plotting Results
TP = (scaled_df['is_fraud'] == 1) & (scaled_df['predicted_fraud'] == 1)
TN = (scaled_df['is_fraud'] == 0) & (scaled_df['predicted_fraud'] == 0)
FP = (scaled_df['is_fraud'] == 0) & (scaled_df['predicted_fraud'] == 1)
FN = (scaled_df['is_fraud'] == 1) & (scaled_df['predicted_fraud'] == 0)

plt.figure(figsize=(10,10))
plt.scatter(scaled_df[TP][ : , 0], scaled_df[TP][ : , 1], c='green',label='True Positives')
plt.scatter(scaled_df[TN][ : , 0], scaled_df[TN][ : , 1], c='red',label='True Negatives')
plt.scatter(scaled_df[FP][ : , 0], scaled_df[FP][ : , 1], c='yellow',label='True Negatives')
plt.scatter(scaled_df[FN][ : , 0], scaled_df[FN][ : , 1], c='orange',label='True Negatives')
plt.title('DBSCAN Results')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()

"""#### Isolation Forest"""

from sklearn.ensemble import IsolationForest
from sklearn.model_selection import GridSearchCV

# Data Formation
training_forest_df = df_encoded.copy()
training_forest_df = training_forest_df.drop('is_fraud', axis=1)
print('Data Preview:')
print(training_forest_df.head())
scaled_forest_data = StandardScaler().fit_transform(training_forest_df)
scaled_forest_df = pd.DataFrame(scaled_forest_data, columns = training_forest_df.columns)
print('Data Preview:')
print(scaled_forest_df.head())

# Parameter Identificatio
iso = IsolationForest()

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_samples': ['auto', 0.5, 1.0],
    'contamination': [0.001, 0.005, 0.01],
    'random_satae' : [310]
}

gridsearch_forest = GridSearchCV(iso, param_grid, cv=5)
gridsearch_forest.fit(scaled_forest_df)

best_perams_forest = gridsearch_forest.best_params_
print(f"Best Parameters: {best_perams_forest}")

# Final Model
iso_model = IsolationForest(**best_perams_forest)
iso_model.fit(scaled_forest_df)
predictions = iso_model.predict(scaled_forest_df)
scaled_forest_df['is_fraud'] = training_forest_df['is_fraud']
for i in range(len(predictions)):
  if predictions[i] == -1:
    predictions[i] = 1
  else:
    predictions[i] = 0
scaled_forest_df['predicted_fraud'] = predictions
print('Data Preview:')
print(scaled_forest_df.head())

# Metrics
report_forest = classification_report(scaled_forest_df['is_fraud'], scaled_forest_df['predicted_fraud'])
print(report_forest)
cm_forest = confusion_matrix(scaled_forest_df['is_fraud'], scaled_forest_df['predicted_fraud'])
plt.figure(figsize=(6,6))
sns.heatmap(cm_forest, fmt='d', cmap='inferno', xticklabels=['Not Fraud', 'Fraud'], yticklabels=['Not Fraud', 'Fraud'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Plotting Results
TP_forest = (scaled_forest_df['is_fraud'] == 1) & (scaled_forest_df['predicted_fraud'] == 1)
TN_forest = (scaled_forest_df['is_fraud'] == 0) & (scaled_forest_df['predicted_fraud'] == 0)
FP_forest = (scaled_forest_df['is_fraud'] == 0) & (scaled_forest_df['predicted_fraud'] == 1)
FN_forest = (scaled_forest_df['is_fraud'] == 1) & (scaled_forest_df['predicted_fraud'] == 0)

plt.figure(figsize=(10,10))
plt.scatter(scaled_forest_df[TP_forest][ : , 0], scaled_forest_df[TP_forest][ : , 1], c='green',label='True Positives')
plt.scatter(scaled_forest_df[TN_forest][ : , 0], scaled_forest_df[TN_forest][ : , 1], c='red',label='True Negatives')
plt.scatter(scaled_forest_df[FP_forest][ : , 0], scaled_forest_df[FP_forest][ : , 1], c='yellow',label='True Negatives')
plt.scatter(scaled_forest_df[FN_forest][ : , 0], scaled_forest_df[FN_forest][ : , 1], c='orange',label='True Negatives')
plt.title('Isolation Forest Results')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()